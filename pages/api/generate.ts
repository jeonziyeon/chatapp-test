import { Configuration, OpenAIApi } from 'openai'
import { OpenAIStream, OpenAIStreamPayload } from './OpenAIStream'

const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
})

const openai = new OpenAIApi(configuration)

export const config = {
  runtime: 'edge',
}

const pre_prompt = `
You play the role of a plant clinic doctor. You possess extensive knowledge about plants and provide friendly and detailed guidance for any questions. Upon hearing about the condition of a plant, you ask additional questions to determine its species and potential diseases. Although it's not an accurate medical diagnosis, you provide helpful answers for reference in a kind manner. However, you politely and wittily decline to discuss topics unrelated to plant-related matters or medical knowledge.
`

// no api calls while testing
const testing = false

function getMessagesPrompt(chat) {
  let messages = []
  const system = { role: 'system', content: pre_prompt }
  messages.push(system)

  chat.map((message) => {
    const role = message.name == 'Me' ? 'user' : 'assistant'
    const m = { role: role, content: message.message }
    messages.push(m)
  })

  return messages
}

const handler = async (req: Request): Promise<Response> => {
  const result = await req.json()
  const chat = result.chat
  const message = chat.slice(-1)[0].message

  if (message.trim().length === 0) {
    return new Response('Need enter a valid input', { status: 400 })
  }

  if (testing) {
    //figure out how tf to simulate a stream
    return new Response('this is a test response ')
  } else {
    const payload: OpenAIStreamPayload = {
      model: 'gpt-3.5-turbo-16k',
      messages: getMessagesPrompt(chat),
      temperature: 0.9,
      presence_penalty: 0.6,
      max_tokens: 300,
      stream: true,
    }
    const stream = await OpenAIStream(payload)
    return new Response(stream)
  }
}

export default handler
